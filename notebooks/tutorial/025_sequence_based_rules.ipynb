{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Sequences\n",
    "\n",
    "The engine can detect sequential patterns of assertions. As these rules trigger, they get saved into memory as \"arcs\", or partially completed rules. Those arcs wait until they are completed before triggering their assertions.\n",
    "\n",
    "This can be useful in natural language and other real-world situations where it's important to assign meaning to a sequence of assertions that occur one after the other. These sequences can in turn form parts of larger sequences and structures, and you can carry information from the lower sequences and structures into the high-order sequences and structures to build up a structure of meaning.\n",
    "\n",
    "To begin, rev up the engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.insert(1, os.path.abspath('..\\\\..'))\n",
    "from thoughts.rules_engine import RulesEngine\n",
    "from pprint import pprint\n",
    "\n",
    "# start a new engine\n",
    "engine = RulesEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asserting a Partial Sequence\n",
    "\n",
    "Let's try a simple example in matching the sequence of letters A, B, and C.\n",
    "\n",
    "At first let's just assert only A and B and inspect the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B']\n"
     ]
    }
   ],
   "source": [
    "rules = { \"#when\": [\"A\", \"B\", \"C\"], \"#then\": \"FOUND\" }\n",
    "engine.add_rule(rules)\n",
    "\n",
    "result = engine.process([\"A\", \"B\"], extract_conclusions=True)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the incoming assertions were returned, and the rule did not trigger. This makes sense, as the engine is waiting on the final part of the sequence, \"C\".\n",
    "\n",
    "## Asserting the Full Sequence\n",
    "\n",
    "Now let's try asserting the full sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'FOUND']\n"
     ]
    }
   ],
   "source": [
    "result = engine.process([\"A\", \"B\", \"C\"], extract_conclusions=True)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here all three parts, or *constituents*, of the sequence were found. This triggered the final \"FOUND\" fact.\n",
    "\n",
    "But why wasn't 'C' returned in the final result? This is an effect of using the extract_conclusions parameter, which only returns the leaf-node (bottom level) facts that were concluded.\n",
    "\n",
    "Let's take a look at the full tree to make this more apparent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'#assert': 'A', '#conclusions': [], '#seq-end': 1, '#seq-start': 0},\n",
      " {'#assert': 'B', '#conclusions': [], '#seq-end': 2, '#seq-start': 1},\n",
      " {'#assert': 'C',\n",
      "  '#conclusions': [{'#assert': 'FOUND',\n",
      "                    '#conclusions': [],\n",
      "                    '#seq': [{'#assert': 'A', '#seq-end': 1, '#seq-start': 0},\n",
      "                             {'#assert': 'B', '#seq-end': 2, '#seq-start': 1},\n",
      "                             {'#assert': 'C', '#seq-end': 3, '#seq-start': 2}],\n",
      "                    '#seq-end': 3,\n",
      "                    '#seq-start': 0}],\n",
      "  '#seq-end': 3,\n",
      "  '#seq-start': 2}]\n"
     ]
    }
   ],
   "source": [
    "result = engine.process([\"A\", \"B\", \"C\"], extract_conclusions=False)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, 'A' and 'B' have no sub-conclusions, so they are returned. 'C' has the sub-conclusion of 'FOUND' and so it is *not* returned. 'FOUND' has no sub-conclusions, so it is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Arcs\n",
    "\n",
    "Now let's run the rule again but this time we'll inspect the partial rules, or arcs, which are waiting on the next constituent in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'#when': [{'#assert': 'A', '#seq-start': 0, '#seq-end': 1}, 'B', 'C'],\n",
      "  '#then': 'FOUND',\n",
      "  '#seq-idx': 1,\n",
      "  '#seq-start': 0,\n",
      "  '#seq-end': 1,\n",
      "  '#unification': {'?#when': {'#assert': 'A', '#seq-start': 0, '#seq-end': 1}},\n",
      "  '#is-arc': True},\n",
      " {'#when': [{'#assert': 'A', '#seq-start': 0, '#seq-end': 1},\n",
      "            {'#assert': 'B', '#seq-start': 1, '#seq-end': 2},\n",
      "            'C'],\n",
      "  '#then': 'FOUND',\n",
      "  '#seq-idx': 2,\n",
      "  '#seq-start': 0,\n",
      "  '#seq-end': 2,\n",
      "  '#unification': {'?#when': {'#assert': 'B', '#seq-start': 1, '#seq-end': 2}},\n",
      "  '#is-arc': True}]\n"
     ]
    }
   ],
   "source": [
    "result = engine.process([\"A\", \"B\"], extract_conclusions=True)\n",
    "\n",
    "pprint(engine.context.arcs, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, there are two entries in the partial rules. Notice the system-generated #seq-idx, #seq-start, and #seq-end attributes.\n",
    "\n",
    "The first entry has detected the 'A' constituent, \"covering\" positions 0 and 1. The rule is \"sitting\" at index position 1, meaning that it's waiting for the constiuent at that position, which in this example is 'B'. \n",
    "\n",
    "The second entry has detected the 'B' consituent, and has extended the original arc by covering the position from 0 to 2, which includes both the 'A' and 'B' positions. the index is sitting at position 2, meaning that it's waiting for the 'C' constituent.\n",
    "\n",
    "*In general, you can think of the arcs as both \"covering\" positions and \"sitting\" at the last position, waiting on the next constituent to arrive.*\n",
    "\n",
    "Also note that *both* arcs are kept in the partial rules. The engine keeps all partial matches to rules, even after extending an arc. This is how it keeps a list of all possibilities, in case another constituent arrives which could also match the rule.\n",
    "\n",
    "Finally, the arcs are cleared by the engine automatically each time the process function runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constituents Must Follow Immediately After Each Other\n",
    "\n",
    "By default, the engine will only detect sequences where the next token constituent is immediately following the previous constituent. \n",
    "\n",
    "It assigns a #seq-start and #seq-end token to facts as they are asserted in the process function. Then it compares to make sure the fact immediately follows the previous constituent in the arc, based on the #seq-end and #seq-start positions. \n",
    "\n",
    "Compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'FOUND']\n"
     ]
    }
   ],
   "source": [
    "result = engine.process([\"A\", \"B\", \"C\"], extract_conclusions=True)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'D', 'C']\n"
     ]
    }
   ],
   "source": [
    "result = engine.process([\"A\", \"B\", \"D\", \"C\"], extract_conclusions=True)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because \"C\" was not immediately following \"A\" and \"B\", the sequence is not detected.\n",
    "\n",
    "We'll see below how to chance this default behavior to allow for \"junk\" in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlapping Sequences are Detected\n",
    "\n",
    "Sequences can overlap each other. This works differently than Sets, which by default prevent the same constituent from being matched multiple times in the same rule. See the tutorial on Sets for more details.\n",
    "\n",
    "The rule below looks for any ABA sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'FOUND', 'B', 'FOUND']\n"
     ]
    }
   ],
   "source": [
    "rule = { \"#when\": [\"A\", \"B\", \"A\"], \"#then\": \"FOUND\" }\n",
    "engine.clear_rules()\n",
    "engine.add_rule(rule)\n",
    "\n",
    "result = engine.process([\"A\", \"B\", \"A\", \"B\", \"A\"], extract_conclusions=True)\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ABA sequence appears twice in the assertion ABABA, so the rule triggers twice. The middle \"A\" is part of both sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allowing Disconnected Sequences (aka Junk in Sequences)\n",
    "\n",
    "By default, sequence matching requires that tokens immediately follow each other, with no \"junk\" tokens in between. You can change this behavior to allow junk by using the #allow-junk attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'D', 'E', 'F', 'FOUND']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule = { \"#when\": [\"A\", \"B\", \"C\"], \n",
    "         \"#seq-type\": \"allow-junk\", \n",
    "         \"#then\": \"FOUND\" }\n",
    "\n",
    "engine.clear_rules()\n",
    "engine.add_rule(rule)\n",
    "engine.process([\"A\", \"B\", \"D\", \"E\", \"F\", \"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allowing junk in sequences may at first appear to \"overmatch\" and generate more sequences than you expect. \n",
    "\n",
    "Consider the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'X', 'A', 'B', 'FOUND', 'FOUND', 'FOUND']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule = { \"#when\": [\"A\", \"B\", \"C\"], \n",
    "         \"#seq-type\": \"allow-junk\", \n",
    "         \"#then\": \"FOUND\" }\n",
    "\n",
    "engine.clear_rules()\n",
    "engine.add_rule(rule)\n",
    "engine.process([\"A\", \"B\", \"X\", \"A\", \"B\", \"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance it looks like there are two valid A B C sequences in A B X A B C - the sequence starting in the with the intitial A B and completed by the final C, and the A B C sequence at the end.\n",
    "\n",
    "However, if you look closely, there are actually three valid sequences of A B C:\n",
    "\n",
    "+ A B . . . C\n",
    "+ A . . . B C\n",
    "+ . . . A B C\n",
    "\n",
    "For this reason, use the #allow-junk rule carefully to make sure you are getting the results you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Sequence-based rules are a powerful way for the engine to wait on information to arrive before making conclusions (triggering rules).\n",
    "\n",
    "Next we'll see a way to detect Sets, where the order the information arrives does not matter."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2131daa06b04808fa66558f781445fffc86a65c38e9ddc639756511472fbc9cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('thoughts-dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
